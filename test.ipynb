{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframe-topic_0_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2024-09-09T02:26:53Z\n",
      "1      2024-09-06T04:19:10Z\n",
      "2      2024-09-06T04:18:55Z\n",
      "3      2024-08-24T20:37:39Z\n",
      "4      2024-08-24T20:33:19Z\n",
      "               ...         \n",
      "572    2019-03-07T05:50:08Z\n",
      "573    2019-03-07T05:41:45Z\n",
      "574    2019-03-07T05:34:31Z\n",
      "575    2019-03-07T05:27:17Z\n",
      "576    2019-03-06T12:48:53Z\n",
      "Name: added_at, Length: 577, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot supply both a tz and a timezone-naive dtype (i.e. datetime64[ns])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(df[col])\n\u001b[1;32m---> 33\u001b[0m     df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39;49mastype(dtype)\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors) \u001b[39mfor\u001b[39;00m _, ser \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan not squeeze with more than one column.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m, :]  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:110\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_np_dtype(dtype, \u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    108\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m \u001b[39mimport\u001b[39;00m DatetimeArray\n\u001b[1;32m--> 110\u001b[0m     dta \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39;49m_from_sequence(arr, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m dta\u001b[39m.\u001b[39m_ndarray\n\u001b[0;32m    113\u001b[0m \u001b[39melif\u001b[39;00m lib\u001b[39m.\u001b[39mis_np_dtype(dtype, \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:327\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence\u001b[1;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_sequence\u001b[39m(\u001b[39mcls\u001b[39m, scalars, \u001b[39m*\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_sequence_not_strict(scalars, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:379\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m    369\u001b[0m subarr, tz \u001b[39m=\u001b[39m _sequence_to_dt64(\n\u001b[0;32m    370\u001b[0m     data,\n\u001b[0;32m    371\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m     out_unit\u001b[39m=\u001b[39munit,\n\u001b[0;32m    377\u001b[0m )\n\u001b[0;32m    378\u001b[0m \u001b[39m# We have to call this again after possibly inferring a tz above\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m _validate_tz_from_dtype(dtype, tz, explicit_tz_none)\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m explicit_tz_none:\n\u001b[0;32m    381\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassed data is timezone-aware, incompatible with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtz=None\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse obj.tz_localize(None) instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\suhu\\src\\spotify-de-pipeline\\spotify-de\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2615\u001b[0m, in \u001b[0;36m_validate_tz_from_dtype\u001b[1;34m(dtype, tz, explicit_tz_none)\u001b[0m\n\u001b[0;32m   2611\u001b[0m     \u001b[39mif\u001b[39;00m tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m lib\u001b[39m.\u001b[39mis_np_dtype(dtype, \u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2612\u001b[0m         \u001b[39m# We also need to check for the case where the user passed a\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m         \u001b[39m#  tz-naive dtype (i.e. datetime64[ns])\u001b[39;00m\n\u001b[0;32m   2614\u001b[0m         \u001b[39mif\u001b[39;00m tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m timezones\u001b[39m.\u001b[39mtz_compare(tz, dtz):\n\u001b[1;32m-> 2615\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2616\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mcannot supply both a tz and a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2617\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtimezone-naive dtype (i.e. datetime64[ns])\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2618\u001b[0m             )\n\u001b[0;32m   2620\u001b[0m \u001b[39mreturn\u001b[39;00m tz\n",
      "\u001b[1;31mValueError\u001b[0m: cannot supply both a tz and a timezone-naive dtype (i.e. datetime64[ns])"
     ]
    }
   ],
   "source": [
    "def infer_dtype(series):\n",
    "    try:\n",
    "        # Try to convert to numeric\n",
    "        numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "        \n",
    "        # Check if all values were successfully converted\n",
    "        if numeric_series.notnull().all():\n",
    "            # Check if all values are integers\n",
    "            if (numeric_series % 1 == 0).all():\n",
    "                return 'int64'\n",
    "            else:\n",
    "                return 'float64'\n",
    "        \n",
    "        # Try to convert to datetime\n",
    "        datetime_series = pd.to_datetime(series, errors='coerce')\n",
    "        if datetime_series.notnull().all():\n",
    "            return 'datetime64[ns]'\n",
    "        \n",
    "        # If not numeric or datetime, assume string\n",
    "        return 'string'\n",
    "    except:\n",
    "        # If any error occurs, assume object\n",
    "        return 'object'\n",
    "\n",
    "# Apply the function to each object column\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "inferred_dtypes = {col: infer_dtype(df[col]) for col in object_columns}\n",
    "\n",
    "# Update the DataFrame with inferred types\n",
    "for col, dtype in inferred_dtypes.items():\n",
    "    if dtype != 'object':\n",
    "        print(df[col])\n",
    "        df[col] = df[col].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>popularity</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>added_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golden hour - Fujii Kaze Remix</td>\n",
       "      <td>JVKE</td>\n",
       "      <td>golden hour (Fujii Kaze Remix)</td>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>159000</td>\n",
       "      <td>61</td>\n",
       "      <td>6KxgptZSrQC4Vv21ZBOG7S</td>\n",
       "      <td>spotify:track:6KxgptZSrQC4Vv21ZBOG7S</td>\n",
       "      <td>2024-09-09T02:26:53Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rodeo13</td>\n",
       "      <td>梅田サイファー</td>\n",
       "      <td>Unfold Collective</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>193106</td>\n",
       "      <td>43</td>\n",
       "      <td>0boflQ50Hu6Gil4n51iWF2</td>\n",
       "      <td>spotify:track:0boflQ50Hu6Gil4n51iWF2</td>\n",
       "      <td>2024-09-06T04:19:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BE THE MONSTER</td>\n",
       "      <td>梅田サイファー</td>\n",
       "      <td>BE THE MONSTER</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>170133</td>\n",
       "      <td>41</td>\n",
       "      <td>2vXeK0sw7rosotTVRN0wsQ</td>\n",
       "      <td>spotify:track:2vXeK0sw7rosotTVRN0wsQ</td>\n",
       "      <td>2024-09-06T04:18:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can't Breakup Girl, Can't Breakaway Boy (feat....</td>\n",
       "      <td>Leessang</td>\n",
       "      <td>Hexagonal</td>\n",
       "      <td>2009-10-06</td>\n",
       "      <td>284626</td>\n",
       "      <td>34</td>\n",
       "      <td>5ob1r8AE5Nbov65ea7P4e4</td>\n",
       "      <td>spotify:track:5ob1r8AE5Nbov65ea7P4e4</td>\n",
       "      <td>2024-08-24T20:37:39Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love Love Love</td>\n",
       "      <td>Epik High</td>\n",
       "      <td>Remapping the Human Soul</td>\n",
       "      <td>2007-01-24</td>\n",
       "      <td>231093</td>\n",
       "      <td>45</td>\n",
       "      <td>7hlEhmg5h9XuFtaGfgvqjF</td>\n",
       "      <td>spotify:track:7hlEhmg5h9XuFtaGfgvqjF</td>\n",
       "      <td>2024-08-24T20:33:19Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name     artist  \\\n",
       "0                     golden hour - Fujii Kaze Remix       JVKE   \n",
       "1                                            Rodeo13    梅田サイファー   \n",
       "2                                     BE THE MONSTER    梅田サイファー   \n",
       "3  Can't Breakup Girl, Can't Breakaway Boy (feat....   Leessang   \n",
       "4                                     Love Love Love  Epik High   \n",
       "\n",
       "                            album release_date  duration_ms  popularity  \\\n",
       "0  golden hour (Fujii Kaze Remix)   2023-04-21       159000          61   \n",
       "1               Unfold Collective   2024-08-28       193106          43   \n",
       "2                  BE THE MONSTER   2023-12-20       170133          41   \n",
       "3                       Hexagonal   2009-10-06       284626          34   \n",
       "4        Remapping the Human Soul   2007-01-24       231093          45   \n",
       "\n",
       "                       id                                   uri  \\\n",
       "0  6KxgptZSrQC4Vv21ZBOG7S  spotify:track:6KxgptZSrQC4Vv21ZBOG7S   \n",
       "1  0boflQ50Hu6Gil4n51iWF2  spotify:track:0boflQ50Hu6Gil4n51iWF2   \n",
       "2  2vXeK0sw7rosotTVRN0wsQ  spotify:track:2vXeK0sw7rosotTVRN0wsQ   \n",
       "3  5ob1r8AE5Nbov65ea7P4e4  spotify:track:5ob1r8AE5Nbov65ea7P4e4   \n",
       "4  7hlEhmg5h9XuFtaGfgvqjF  spotify:track:7hlEhmg5h9XuFtaGfgvqjF   \n",
       "\n",
       "               added_at  \n",
       "0  2024-09-09T02:26:53Z  \n",
       "1  2024-09-06T04:19:10Z  \n",
       "2  2024-09-06T04:18:55Z  \n",
       "3  2024-08-24T20:37:39Z  \n",
       "4  2024-08-24T20:33:19Z  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name object\n",
      "artist object\n",
      "album object\n",
      "release_date object\n",
      "duration_ms int64\n",
      "popularity int64\n",
      "id object\n",
      "uri object\n",
      "added_at object\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col, df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('user_followed_artists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_dtype(series):\n",
    "    try:\n",
    "        # Try to convert to numeric\n",
    "        numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "        \n",
    "        # Check if all values were successfully converted\n",
    "        if numeric_series.notnull().all():\n",
    "            # Check if all values are integers\n",
    "            if (numeric_series % 1 == 0).all():\n",
    "                return 'int64'\n",
    "            else:\n",
    "                return 'float64'\n",
    "        \n",
    "        # Try to convert to datetime\n",
    "        datetime_series = pd.to_datetime(series, errors='coerce')\n",
    "        if datetime_series.notnull().all():\n",
    "            return 'datetime64[ns]'\n",
    "        \n",
    "        # If not numeric or datetime, assume string\n",
    "        return 'string'\n",
    "    except:\n",
    "        # If any error occurs, assume object\n",
    "        return 'object'\n",
    "\n",
    "# Apply the function to each object column\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "inferred_dtypes = {col: infer_dtype(df[col]) for col in object_columns}\n",
    "\n",
    "# Update the DataFrame with inferred types\n",
    "for col, dtype in inferred_dtypes.items():\n",
    "    if dtype != 'object':\n",
    "        df[col] = df[col].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>popularity</th>\n",
       "      <th>genres</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cö shu Nie</td>\n",
       "      <td>0LlH6J1tj2TPq7AlwXAkY5</td>\n",
       "      <td>spotify:artist:0LlH6J1tj2TPq7AlwXAkY5</td>\n",
       "      <td>54</td>\n",
       "      <td>anime, j-pixie</td>\n",
       "      <td>325726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epic Rap Battles of History</td>\n",
       "      <td>0Rq2hV3S3O4JMWbL2B510w</td>\n",
       "      <td>spotify:artist:0Rq2hV3S3O4JMWbL2B510w</td>\n",
       "      <td>51</td>\n",
       "      <td>antiviral pop, comic</td>\n",
       "      <td>411897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAMAMOO</td>\n",
       "      <td>0XATRDCYuuGhk0oE7C0o5G</td>\n",
       "      <td>spotify:artist:0XATRDCYuuGhk0oE7C0o5G</td>\n",
       "      <td>61</td>\n",
       "      <td>k-pop, k-pop girl group</td>\n",
       "      <td>7338710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jon-YAKITORY</td>\n",
       "      <td>0XDvcwWavm2VcdiXwDKgvB</td>\n",
       "      <td>spotify:artist:0XDvcwWavm2VcdiXwDKgvB</td>\n",
       "      <td>54</td>\n",
       "      <td>anime</td>\n",
       "      <td>103609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aimer</td>\n",
       "      <td>0bAsR2unSRpn6BQPEnNlZm</td>\n",
       "      <td>spotify:artist:0bAsR2unSRpn6BQPEnNlZm</td>\n",
       "      <td>66</td>\n",
       "      <td>anime, anime rock, j-pixie, j-pop, j-poprock</td>\n",
       "      <td>2513566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name                      id  \\\n",
       "0                   Cö shu Nie  0LlH6J1tj2TPq7AlwXAkY5   \n",
       "1  Epic Rap Battles of History  0Rq2hV3S3O4JMWbL2B510w   \n",
       "2                      MAMAMOO  0XATRDCYuuGhk0oE7C0o5G   \n",
       "3                 jon-YAKITORY  0XDvcwWavm2VcdiXwDKgvB   \n",
       "4                        Aimer  0bAsR2unSRpn6BQPEnNlZm   \n",
       "\n",
       "                                     uri  popularity  \\\n",
       "0  spotify:artist:0LlH6J1tj2TPq7AlwXAkY5          54   \n",
       "1  spotify:artist:0Rq2hV3S3O4JMWbL2B510w          51   \n",
       "2  spotify:artist:0XATRDCYuuGhk0oE7C0o5G          61   \n",
       "3  spotify:artist:0XDvcwWavm2VcdiXwDKgvB          54   \n",
       "4  spotify:artist:0bAsR2unSRpn6BQPEnNlZm          66   \n",
       "\n",
       "                                         genres  followers  \n",
       "0                                anime, j-pixie     325726  \n",
       "1                          antiviral pop, comic     411897  \n",
       "2                       k-pop, k-pop girl group    7338710  \n",
       "3                                         anime     103609  \n",
       "4  anime, anime rock, j-pixie, j-pop, j-poprock    2513566  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify-de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
